---
title: "lobster density"
author: "TimLanglois"
date: "09/01/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#BIOL4408 Marine Ecology - lobster density


## 0. Import lobster density data from a google sheet


First we need to load some librarys

```{r libs1, message=FALSE, warning=FALSE}
library(googlesheets4) #to read gsheet
library(tidyr) #to tody data
library(dplyr) #to transform data
library(readr) #to write data
library(here) #to make robust links to files
```

It is useful to set a study name
```{r name, message=FALSE, warning=FALSE}
study<-"lobster.density"
```


Read in the data from the google sheet and check it
```{r read, message=FALSE, warning=FALSE}
#We need the URL for the google sheet
url <- "https://docs.google.com/spreadsheets/d/1Wqn7m2jopx11n5fdl9MHZAujRVkjBusdmIHq_gMhf0A/edit#gid=25814706"

# Then we can read it in
dat<-read_sheet(url, sheet = "lobster.density")%>%
  as_tibble()%>%
  select(-c('longitude','latitude','time','way.point','gps','depth','group'))%>%
  glimpse()
```


Now we need to write the data.

There are several ways to setting the directory where we will read data from or write data to.

We are going to use the here() function.

As long as the names on the folders are consistent this function will enable us to work across computers and operating systems.

```{r here, message=FALSE, warning=FALSE}
data.dir<-here("Analysis_Lobster_density","Data")
dir()
```


Now to write the data we have imported from the googlesheet.
We will append the study name.
```{r write, message=FALSE, warning=FALSE}
setwd(data.dir)#this is out shortcut using here()
dir()

write_csv(dat,paste(study,"gsheet","csv",sep = "."))

```


## 1. Check the lobster density data and make some quick plots

Load some extra librarys

```{r libs2, message=FALSE, warning=FALSE}
library(forcats) #to transform catagorical data
library(ggplot2) #to plot data
```


Read in the data and glimpse the variable names, formats, head of the data
```{r read, message=FALSE, warning=FALSE}
setwd(data.dir)#this is out shortcut using here()
dir()

gsheet.dat<-read_csv("lobster.density.gsheet.csv")%>%
  glimpse()

```


Check for unique levels of status
```{r check status, message=FALSE, warning=FALSE}
unique(gsheet.dat$status)
```
there is a typo

Check for unique levels of sanctuary
```{r check sanct, message=FALSE, warning=FALSE}
unique(gsheet.dat$sanctuary)

```

Check for unique levels of site
```{r check site, message=FALSE, warning=FALSE}
unique(gsheet.dat$site)

```
"eastsalmon" should be "Salmon Bay"


Check for unique levels of year
```{r check year, message=FALSE, warning=FALSE}
unique(gsheet.dat$year)

```
we are worried about 2017 - we should remove it


Check measures of habitat complexity
```{r check complex, message=FALSE, warning=FALSE}
unique(gsheet.dat$complexity)

summary(gsheet.dat$complexity)

```
looks ok


Check measures of habitat cover
```{r check cover, message=FALSE, warning=FALSE}
unique(gsheet.dat$algal.cover)

summary(gsheet.dat$algal.cover)

unique(filter(gsheet.dat,year=="2019")$algal.cover)

```
does not look consistent - suggest you only use the most recent years of data


Check what sites are missing between years
```{r check sites, message=FALSE, warning=FALSE}
table(gsheet.dat$site,gsheet.dat$year)
```
"Armstrong Point","Longreach","Rocky Bay","Stark Bay" - are only sampled once and we should remove them



Check how we have used site names - are they unique between levels of status?
```{r check sites, message=FALSE, warning=FALSE}
table(gsheet.dat$year,gsheet.dat$status)
```

OK with have some corrections to make.
It is always good to have our source data as 'correct' as possible.
But by making these corrections in our R import script we will be able to keep a record of the changes/corrections we are making to the data.


Make corrections and re-format
```{r check sites, message=FALSE, warning=FALSE}

dat<-gsheet.dat %>%
  dplyr::mutate(status = fct_recode(status,
                                    "No-take" = "No-Take"))%>%
  dplyr::mutate(sanctuary = fct_recode(sanctuary,
                                    "Parker Point" = "Parker_Pt",
                                    "Green Island" = "Green_Island",
                                    "Armstrong Bay" = "Armstrong"))%>%
  
#recode the site names
  
    dplyr::mutate(site = fct_recode(site,
                           "Salmon Bay" = "eastsalmon",
                           "City of York" = "City of York Bay",
                           "Ricey Beach" = "Ricey_Bay",
                           "Salmon Bay" = "East_Salmon",
                           "Little Salmon" = "Little_Salmon",
                           "Parker Point" = "Poc_Reef",
                           "Green Island" = "Green_Island",
                           "Parakeet Bay" = "Parakeet_Bay",
                           "Salmon Bay" = "West_Salmon_Bay",
                           "Little Armstrong" = "Little_Armstrong_Bay",
                           "Geordie Bay" = "Geordie_Bay",
                           "Mary Cove" = "Mary_Cove",
                           "Strickland Bay" = "East_Strickland"))%>%
    
  #filter out sites only done once
    filter(!site%in%c(
    "Armstrong Point",
    "Longreach",
    "Rocky Bay",
    "Stark Bay"))%>%
  
  #filter out suspicous year  
    filter(!year==2017)%>%
  
  #remove the levels for the filtered facotrs
    droplevels()%>%
  
  # Make a new unique Site namename
  dplyr::mutate(site.new=paste(site,status,sep="."))%>%
  
    glimpse()

```


Now we can check our corections
```{r check sites, message=FALSE, warning=FALSE}

unique(dat$sanctuary) 

unique(dat$site) 

unique(dat$status)

str(dat)



```





# Use dat and make new varialbes for sum of legal and sub.legal-----
dat<-gsheet.dat%>% 
  dplyr::mutate(status = fct_recode(status,
                                    "No-take" = "No-Take"))%>%
  dplyr::mutate(sanctuary = fct_recode(sanctuary,
                                       "Parker Point" = "Parker_Pt",
                                       "Green Island" = "Green_Island",
                                       "Armstrong Bay" = "Armstrong"))%>%
  dplyr::mutate(site = fct_recode(site,
                                  "Salmon Bay" = "eastsalmon",
                                  "City of York" = "City of York Bay",
                                  "Ricey Beach" = "Ricey_Bay",
                                  "Salmon Bay" = "East_Salmon",
                                  "Little Salmon" = "Little_Salmon",
                                  "Parker Point" = "Poc_Reef",
                                  "Green Island" = "Green_Island",
                                  "Parakeet Bay" = "Parakeet_Bay",
                                  "Salmon Bay" = "West_Salmon_Bay",
                                  "Little Armstrong" = "Little_Armstrong_Bay",
                                  "Geordie Bay" = "Geordie_Bay",
                                  "Mary Cove" = "Mary_Cove",
                                  "Strickland Bay" = "East_Strickland"))%>%
  filter(!site%in%c(
    "Armstrong Point",
    # "Longreach",
    "Rocky Bay",
    "Stark Bay"))%>%
  filter(!year==2017)%>%
  droplevels()%>%
  # replace(is.na(.), 0)%>%
  
  mutate_at(vars(starts_with("x")), funs(ifelse(is.na(.),0,.)))%>%
  mutate_at(vars(starts_with("unsi")), funs(ifelse(is.na(.),0,.)))%>%
  mutate_at(vars(starts_with("legal")), funs(ifelse(is.na(.),0,.)))%>%
  mutate_at(vars(starts_with("sub")), funs(ifelse(is.na(.),0,.)))%>%
  
  # mutate_at(vars(ends_with("delay")), funs(abs, round))
  dplyr::mutate(site.new=paste(site,status,sep="."))%>%
  # make the legal sum
  dplyr::mutate(legal=(legal.unsized+x80+x85+x90+x95+x100+x105+x110+x115+x120+x125+x130+x135+x140+x145+x150))%>%
  # make the sub.legal sum
  dplyr::mutate(sub.legal=(sublegal.unsized+x25+x30+x35+x40+x45+x50+x55+x60+x65+x70+x75))%>%
  dplyr::mutate(all=(legal+sub.legal+unsized))%>%
  # make a unique sample number
  dplyr::mutate(sample.no=1:nrow(.))%>%
  # select the variables of interest
  select(c(sample.no,year,date,sanctuary,status,site.new,complexity,algal.cover,legal,sub.legal,all))%>%
  # # # make the data long again
  gather(key="size.class",value="count",legal, sub.legal,all)%>%
  glimpse()




# Write the long data----

setwd(data.dir) #set the directory
dir() #look in the directory
write.csv(dat,"dat.csv")

# Write dat using study name and system date
write_csv(dat,paste(study,"csv",sep = "."))





# Basic plots to check out the data----


# Point plot----
ggplot(data=dat, aes(x=status, y=count)) + 
  geom_point()


# Jittered point plot (great for checking data)----
ggplot(dat, aes(x=status, y=count)) + 
  geom_point(position = position_jitter(),alpha = 1/4) #alpha gives transparency


# Jittered point plot with one factor facetted----
ggplot(dat, aes(x=status, y=count)) + 
  geom_point(position = position_jitter(),alpha = 1/4)+
  facet_grid(.~year) #facet by factor


#jittered point plot with two factors faceted-----
ggplot(dat, aes(x=status, y=count, colour=status)) + 
  geom_point(position = position_jitter(width = 0.1, h = 0),alpha = 1/4)+
  facet_grid(size.class~year)


# Box plot (does not look very good!)----
ggplot(dat, aes(x=status, y=count)) + 
  geom_boxplot(outlier.shape = NA, notch=FALSE, width=0.8)+
  geom_point(position = position_jitter(width = 0.1, h = 0),alpha = 1/4, size=1)+
  stat_summary(fun.y=mean, geom="point", shape=2, size=4)+ #adds mean
  facet_grid(size.class~sanctuary)




